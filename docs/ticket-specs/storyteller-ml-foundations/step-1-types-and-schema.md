# Step 1: Prediction Types and Feature Schema

**Status**: Complete
**Date**: 2026-02-07

## What was built

### 1. Raw ML Output Types (`storyteller-core/src/types/prediction.rs`)

Split prediction types into two tiers:

**Raw types** (ML model output — enums + floats only, no natural language):

| Type | Fields | Purpose |
|------|--------|---------|
| `RawActionPrediction` | action_type, confidence, target, emotional_valence, action_context | What the character does |
| `RawSpeechPrediction` | occurs, register, confidence | Whether and how they speak |
| `RawThoughtPrediction` | awareness_level, dominant_emotion_index | Internal state |
| `RawEmotionalDelta` | primary_index, intensity_change, awareness_shifts | Emotional shifts |
| `RawActivatedTensorFrame` | activated_axis_indices, confidence | Which tensor axes matter |
| `RawCharacterPrediction` | Composed of all the above | Complete ML output |
| `ActionContext` (enum) | SharedHistory, CurrentScene, EmotionalReaction, RelationalDynamic, WorldResponse | Tells assembly where to look |

**Assembled types** (unchanged signatures, clarified documentation):
- All `String` fields documented as "Generated by context assembly, NOT by the ML model"
- Added `target: Option<EntityId>` to `ActionPrediction`
- Downstream consumers (Resolver, GameDesignSystem) unchanged

### 2. Feature Encoding Schema (`storyteller-ml/src/feature_schema.rs`)

The shared contract between Rust inference (ort) and Python training (PyTorch).

**Input encoding** — 453 features in 7 named regions:

| Region | Features | Encoding |
|--------|----------|----------|
| Tensor axes | 208 | 16 slots × (AxisValue[4] + TemporalLayer[4] + Provenance[5]) |
| Emotional state | 48 | 8 primaries × (intensity[1] + AwarenessLevel[5]) |
| Self-edge | 7 | trust(3) + affection + debt + history_weight + projection_accuracy |
| Relational edges | 120 | 5 slots × (substrate[20] + TopologicalRole[4]) |
| Scene context | 6 | SceneType[4] + cast_size + tension |
| Player event | 16 | EventType[7] + EmotionalRegister[7] + confidence + target_count |
| History | 48 | 3 turns × (ActionType[6] + SpeechRegister[4] + AwarenessLevel[5] + valence) |

**Output decoding** — 42 features in 4 heads:

| Head | Features | Encoding |
|------|----------|----------|
| Action | 14 | ActionType[6] + confidence + target_index + valence + ActionContext[5] |
| Speech | 6 | occurs + SpeechRegister[4] + confidence |
| Thought | 6 | AwarenessLevel[5] + dominant_emotion |
| Emotion | 16 | intensity_deltas[8] + awareness_shifts[8] |

**Public API**:
- `encode_features(PredictionInput) -> Vec<f32>` — character + context to feature vector
- `decode_outputs(&[f32], EntityId, axis_indices, confidence) -> RawCharacterPrediction`
- `schema_metadata() -> SchemaMetadata` — JSON-exportable for Python

### 3. Crate Skeleton (`storyteller-ml/`)

- Added to workspace with dependencies on storyteller-core, serde, rand, tokio, tracing
- Module structure: `feature_schema`, `matrix/` (archetypes, dynamics, profiles)
- Binary stubs: `generate-training-data`, `validate-dataset`

## Test coverage

- **14 new tests** in feature_schema (encode, decode, roundtrip, edges, history, schema consistency, serialization)
- **7 new tests** for raw prediction types
- **2 updated tests** for assembled types (added `target` field)
- **Total workspace**: 93 tests passing, clippy clean, fmt clean

## Key design decisions

1. **ML model produces only structured values**: No text generation. String fields are populated by context assembly via deterministic graph/tensor enrichment.

2. **ActionContext enum**: Tells the assembly system *why* the character acts, which determines *which* graph data to look up for enrichment. Five categories: SharedHistory, CurrentScene, EmotionalReaction, RelationalDynamic, WorldResponse.

3. **Trivial delta filtering**: `decode_outputs()` filters emotional deltas with |change| < 0.01, reducing noise from the model's tanh outputs.

4. **Target resolution deferred**: The model outputs a target index (cast member position). Resolution to EntityId happens in the caller, not in `decode_outputs()`, because the cast list is context the schema doesn't own.

## What's next

Step 2: Combinatorial matrix — archetype templates, relational dynamics, scene profiles, and the training data generation pipeline.
